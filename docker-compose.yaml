services:
  api:
    image: ghcr.io/like-a-freedom/smolvlm_api:master
    container_name: smolvlm-api
    user: "1000:1000"
    ports:
      - 8000:8000
    volumes:
      - ./model_cache:/app/model_cache
    environment:
      - MODEL_CACHE_DIR=/app/model_cache
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-}
      - QUANTIZE_MODEL=True # Quantize model to reduce memory usage and boost performance to int8, True or False
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: 4G
        # reservations:
        #   devices:
        #     - driver: nvidia
        #       count: all
        #       capabilities: [ gpu ]

volumes:
  model_cache:
